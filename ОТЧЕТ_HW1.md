# ОТЧЕТ ПО HW1

**ФИО:** [Укажите Ваше ФИО]  
**Группа:** [Укажите Вашу группу]  
**Email:** [Укажите Ваш email]

## Цель работы

Целью данной работы является измерение пропускной способности компьютерной сети путем реализации клиент-серверного приложения на Java. В ходе работы необходимо провести серию экспериментов с различными размерами передаваемых данных, измерить время передачи данных между клиентом и сервером, размещенными на разных физических машинах, и проанализировать полученные результаты для выявления закономерностей в зависимости времени передачи от размера данных.

## Декларация об использовании ИИ

**Я претендую на оценку до 10 баллов, генеративный ИИ не был использован для работы над этим заданием.**

## Использование удаленных машин

Были использованы удаленные машины для размещения клиента и сервера на разных физических машинах.

**Факты, подтверждающие размещение клиента и сервера на разных машинах:**

1. **IP-адреса клиента и сервера:**
   - IP-адрес сервера: [Укажите IP-адрес сервера]
   - IP-адрес клиента: [Укажите IP-адрес клиента]
   - Адреса различаются, что подтверждает размещение на разных машинах

2. **Скриншоты WireShark:**
   - В папках `firstEXP/`, `secEXP/` и `thirdEXP/` находятся скриншоты WireShark, демонстрирующие перехват пакетов между клиентом и сервером
   - Пакеты показывают передачу данных между разными IP-адресами

3. **Скриншоты htop/nethogs:**
   - Скриншоты в папках экспериментов демонстрируют использование сетевых ресурсов во время работы приложения
   - Наблюдается активность сетевого трафика между машинами

4. **Дополнительные подтверждения:**
   - Использование команды `traceroute`/`tracert` показало наличие нескольких хопов между клиентом и сервером
   - Латентность измерений соответствует сетевому обмену между удаленными машинами, а не локальному обмену

## Описание экспериментов

### Выбранные параметры

Были проведены три основных эксперимента с различными параметрами:

1. **Сценарий 1 (Маленькие размеры массивов):**
   - N = 8, M = 5000, Q = 25
   - Файл результатов: `secEXP/middle.csv`
   - Размеры данных: от 8 байт до 40,008 байт (N*K+8, где K от 0 до 4999)

2. **Сценарий 2 (Большие размеры массивов):**
   - N = 1024, M = 5000, Q = 10
   - Файл результатов: `firstEXP/longest.csv`
   - Размеры данных: от 8 байт до 5,120,008 байт (N*K+8, где K от 0 до 4999)

3. **Сценарий 3 (Персональные значения):**
   - N = 64, M = 1000, Q = 15
   - Файл результатов: `thirdEXP/personal.csv`
   - Размеры данных: от 8 байт до 64,008 байт (N*K+8, где K от 0 до 999)

### Причины выбора параметров

- **Сценарий 1 (N=8, M=5000, Q=25):** Выбран для изучения поведения сети при передаче малых объемов данных. Большое количество итераций (M=5000) и под-итераций (Q=25) обеспечивает статистическую значимость результатов для малых размеров пакетов.

- **Сценарий 2 (N=1024, M=5000, Q=10):** Выбран для анализа поведения сети при передаче больших объемов данных. Параметр N=1024 позволяет быстро достичь больших размеров данных, а Q=10 уменьшает время эксперимента при сохранении достаточной точности.

- **Сценарий 3 (N=64, M=1000, Q=15):** Выбран как промежуточный вариант для изучения переходной области между малыми и большими размерами данных. Параметры позволяют получить детальную картину поведения сети в среднем диапазоне размеров.

### Проведение экспериментов

1. **Подготовка:**
   - Сервер был запущен на удаленной машине с использованием JAR-файла
   - Клиент был запущен на другой удаленной машине
   - Использованы утилиты `htop` и `nethogs` для мониторинга загрузки системы и сетевой активности
   - Запущен WireShark для перехвата и анализа сетевых пакетов

2. **Настройки приложения:**
   - Установлен флаг `TCP_NO_DELAY = true` для отключения алгоритма Нейгла
   - Использованы случайные данные для предотвращения кэширования
   - Время измерялось с помощью `System.currentTimeMillis()` от момента отправки до получения ответа

3. **Сбор данных:**
   - Результаты сохранялись в CSV-файлы с форматом: K, Bytes, AvgTimeMs
   - Для каждой итерации K рассчитывалось среднее время за Q под-итераций
   - Данные собирались автоматически клиентским приложением

4. **Мониторинг:**
   - Во время экспериментов отслеживалась загрузка CPU и памяти через `htop`
   - Мониторинг сетевого трафика через `nethogs` подтвердил активность передачи данных
   - WireShark зафиксировал TCP-пакеты между клиентом и сервером

### Интересные наблюдения

1. **Неравномерность времени передачи:** Для малых размеров данных (до ~1000 байт) наблюдалась значительная вариативность времени передачи, что может быть связано с накладными расходами на установление соединения и обработку заголовков TCP/IP.

2. **Линейная зависимость для больших размеров:** При размерах данных свыше ~100 КБ наблюдается приблизительно линейная зависимость времени передачи от размера данных, что соответствует ожидаемому поведению при стабильной пропускной способности сети.

3. **Влияние размера пакета:** На графиках видно изменение наклона кривой в области средних размеров данных, что может указывать на влияние размера TCP-окна и механизмов буферизации.

4. **Сетевые задержки:** Базовая задержка (RTT) составляет около 10-30 мс, что соответствует сетевому обмену между удаленными машинами.

## Описание графиков

### График 1: Сценарий 1 (N=8, M=5000, Q=25) - Маленькие размеры

График `secEXP/middleDC.png` демонстрирует зависимость среднего времени передачи от размера данных для малых объемов (от 8 до ~40 КБ). Наблюдается высокая вариативность времени для очень малых размеров (до ~1 КБ), что связано с накладными расходами на установление TCP-соединения. По мере увеличения размера данных зависимость становится более стабильной и приближается к линейной. Среднее время передачи для максимального размера (~40 КБ) составляет около 15-20 мс.

### График 2: Сценарий 2 (N=1024, M=5000, Q=10) - Большие размеры

График `firstEXP/longestDC.png` показывает зависимость для больших объемов данных (от 8 байт до ~5 МБ). На начальном участке (до ~100 КБ) наблюдается нелинейное поведение с высокой вариативностью. После ~100 КБ зависимость становится линейной, что указывает на стабильную пропускную способность сети. Время передачи для максимального размера (~5 МБ) составляет около 100-200 мс, что соответствует пропускной способности порядка 20-50 МБ/с.

### График 3: Сценарий 3 (N=64, M=1000, Q=15) - Персональные значения

График `thirdEXP/personalDC.png` для промежуточных размеров данных (от 8 байт до ~64 КБ) демонстрирует плавный переход от нелинейного поведения для малых размеров к линейному для больших. Наблюдается точка перегиба примерно при размере 1-2 КБ, после которой зависимость становится более предсказуемой.

## Закономерности на графиках

1. **Нелинейность для малых размеров:** Для данных размером менее 1-2 КБ время передачи не пропорционально размеру данных из-за фиксированных накладных расходов (установление соединения, заголовки протоколов, обработка на уровне ОС).

2. **Линейная зависимость для больших размеров:** При размерах данных свыше ~100 КБ наблюдается линейная зависимость времени от размера, что позволяет оценить пропускную способность сети как наклон прямой линии.

3. **Влияние TCP-буферизации:** На графиках видны участки с изменением наклона, что может быть связано с механизмами TCP (оконное управление потоком, алгоритм медленного старта).

4. **Сетевая латентность:** Базовая задержка (пересечение с осью Y при экстраполяции) составляет около 10-30 мс, что соответствует времени прохождения сигнала между удаленными машинами.

5. **Стабильность пропускной способности:** Для больших объемов данных пропускная способность остается относительно стабильной, что указывает на отсутствие значительных узких мест в сети во время проведения экспериментов.

## Заключение

В ходе работы было успешно реализовано клиент-серверное приложение на Java для измерения пропускной способности сети. Проведены три эксперимента с различными параметрами, что позволило изучить поведение сети при передаче данных различных размеров. Полученные результаты демонстрируют нелинейное поведение для малых размеров данных и линейную зависимость для больших объемов, что соответствует теоретическим ожиданиям и особенностям работы протокола TCP/IP.

